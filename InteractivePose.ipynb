{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 1])\n",
      "torch.Size([1, 2, 640000])\n",
      "torch.Size([1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import skimage\n",
    "import imageio\n",
    "import glob\n",
    "\n",
    "\n",
    "from multiPoseExtraction import MultiPoseExtraction\n",
    "from PoseExtraction import PoseNormalization\n",
    "from deepHOG import DeepHOG\n",
    "import utils\n",
    "import datasets as ds\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "def tensor_to_coord_tensor(X):\n",
    "    \"\"\"\n",
    "    Takes in a 4D image and returns the 3*W*H coordinate representation\n",
    "    \"\"\"\n",
    "    device = X.device\n",
    "    batch_num, channel_num, height, width = X.shape\n",
    "    flattened_img = X.permute((0, 1, 3, 2)).contiguous().view(batch_num, -1)\n",
    "    x_coord = torch.arange(0, width).view(width, 1)\n",
    "    x_coord = x_coord.expand(width, height).contiguous()\n",
    "    x_coord = x_coord.view(width * height).float().expand(batch_num, -1).to(device)\n",
    "\n",
    "    y_coord = torch.arange(height, 0, -1) - 1\n",
    "    y_coord = y_coord.expand(width, height).contiguous()\n",
    "    y_coord = y_coord.view(width * height).float().expand(batch_num, -1).to(device)\n",
    "        \n",
    "    coord_matrix = torch.stack([x_coord, y_coord, flattened_img])\n",
    "\n",
    "    return coord_matrix.permute((1, 0, 2))\n",
    "\n",
    "\n",
    "class Noise(torch.nn.Module):\n",
    "    def __init__(self, scale=0.01):\n",
    "        super(Noise, self).__init__()\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        noise = (torch.randn_like(x)*self.scale).to(device)\n",
    "        return x + noise\n",
    "    \n",
    "\n",
    "def plot_arrow_img(ax, means, orientations, img_shape, arrow_scale=2, color=(1, 0, 0), alpha=0.8):\n",
    "    mean_x = means[0].cpu().data.numpy()\n",
    "    mean_y = means[1].cpu().data.numpy()\n",
    "\n",
    "    rot = orientations.cpu().data.numpy()\n",
    "    arrow_start = (mean_x, img_shape[1] - mean_y)\n",
    "    arrow_end = (rot[0]*arrow_scale, -1*rot[1]*arrow_scale)\n",
    "\n",
    "    #         ax[index % row_length].arrow(arrow_start[0], arrow_start[1], arrow_end[0], arrow_end[1], \n",
    "    #                     head_width=0.5, head_length=1, fc='red', ec='r', linewidth=4, alpha=1)\n",
    "\n",
    "    ax.arrow(arrow_start[0], arrow_start[1], arrow_end[0], arrow_end[1], \n",
    "                head_width=arrow_scale/8, head_length=arrow_scale/8, fc='red', ec=color, linewidth=4, alpha=alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_files = glob.glob('./data/HeadPoseImageDatabase/Person02/*.jpg')\n",
    "\n",
    "# im = imageio.imread(img_files[np.random.randint(len(img_files))], as_gray=True)\n",
    "# im = im[20:, 20:-20]\n",
    "\n",
    "im = np.zeros([800, 800])\n",
    "im[10:-700, 480:-20] = 1\n",
    "\n",
    "im[650:-20, 20:-600] = 1\n",
    "\n",
    "# im = ndimage.rotate(im, 34, mode='constant')\n",
    "im = ndimage.gaussian_filter(im, 1)\n",
    "\n",
    "sx = ndimage.sobel(im, axis=0, mode='constant')\n",
    "sy = ndimage.sobel(im, axis=1, mode='constant')\n",
    "sob = np.hypot(sx, sy)\n",
    "# sob = im\n",
    "\n",
    "sob += 0.00*np.random.random(im.shape)\n",
    "\n",
    "def left_svd_tensor(T):\n",
    "    eps = 0.001\n",
    "    device = T.device\n",
    "    # X = torch.bmm(T, torch.bmm(self.weights.expand(T.shape[0], *self.weights.shape).to(device), T.permute(0, 2, 1)))\n",
    "    X = torch.bmm(T, T.permute(0, 2, 1))\n",
    "\n",
    "    D = X[:, 0, 0]* X[:, 1, 1] - X[:, 0, 1]*X[:, 1, 0]\n",
    "    D = D.unsqueeze(1).unsqueeze(2)\n",
    "    X = torch.mul((1 / (D + 0.001)), X)\n",
    "\n",
    "    T = X[:, 0, 0] + X[:, 1, 1]\n",
    "    D = X[:, 0, 0] * X[:, 1, 1] - X[:, 0, 1]*X[:, 1, 0]\n",
    "\n",
    "    L1 = (T + torch.sqrt(torch.nn.functional.relu((T**2) - 4*D))) / 2\n",
    "    L2 = (T - torch.sqrt(torch.nn.functional.relu((T**2) - 4*D))) / 2\n",
    "\n",
    "    v1 = torch.stack([L1 - X[:, 1, 1], X[:, 1, 0]])\n",
    "    v2 = torch.stack([L2 - X[:, 1, 1], X[:, 1, 0]])\n",
    "    U = torch.stack([v1, v2]).permute(2, 0, 1)\n",
    "    U = torch.nn.functional.normalize(U,  dim=2)\n",
    "#     confidence = self.strength_cofficient(L1, L2)\n",
    "    confidence = 1\n",
    "    return U, confidence, L1, L2\n",
    "\n",
    "\n",
    "def get_orientation_vectors(img, mean):\n",
    "    epsilon = 0.0001\n",
    "    coord_tensor = tensor_to_coord_tensor(torch.from_numpy(img).unsqueeze(0).unsqueeze(1).float())\n",
    "    W = torch.abs(coord_tensor[:,2:3,:])\n",
    "    X = coord_tensor[:, :2, :]\n",
    "\n",
    "    WX = torch.mul(W, X)\n",
    "    \n",
    "    mu_avg = (torch.sum(WX, dim=2) / torch.sum(W, dim=2) + epsilon).unsqueeze(2)\n",
    "    mu_W = torch.from_numpy(mean).unsqueeze(0).unsqueeze(2).float()\n",
    "    print(mu_W.shape)\n",
    "    print(X.shape)\n",
    "\n",
    "    XC = X - mu_W\n",
    "    # print(XC.shape)\n",
    "    XC = XC / ((torch.norm(XC, p=1, dim=1)**2))\n",
    "#     XC = XC / (0.1*torch.norm(XC, dim=1))\n",
    "#     XC = XC\n",
    "\n",
    "    WXC = torch.mul(torch.sqrt(W), XC)\n",
    "    WXC = WXC / WXC.sum()\n",
    "\n",
    "    orientations, confidence, L1, L2 = left_svd_tensor(WXC)\n",
    "    \n",
    "    return orientations, (L1, L2), mu_avg\n",
    "\n",
    "# get_orientation_vectors(sob, np.array((50, 50)))\n",
    "\n",
    "img_shape = sob.shape\n",
    "\n",
    "fig ,ax = plt.subplots()\n",
    "ax.imshow(sob)\n",
    "ax.axis('off')\n",
    "ax.set_title('Sobel filter', fontsize=20)\n",
    "\n",
    "def onclick(event):\n",
    "    mean = np.asarray([event.xdata, img_shape[1] - event.ydata])\n",
    "    orientation, (L1, L2), mu_avg = get_orientation_vectors(sob, mean.copy())\n",
    "    print(mu_avg.shape)\n",
    "    mean_position = mu_avg[0, :, 0].numpy()\n",
    "    arrow_scale = (L1 / L2).item()*20\n",
    "    orientation1 = orientation[0, 0, :]\n",
    "    ax.plot(event.xdata, event.ydata, 'r*')\n",
    "    ax.scatter(mean_position[0], img_shape[1] - mean_position[1], s=200, c='g')\n",
    "    plot_arrow_img(ax, torch.Tensor(mean), orientation1, img_shape, color='y', arrow_scale=arrow_scale, alpha=0.8)\n",
    "    plt.draw() #redraw\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
