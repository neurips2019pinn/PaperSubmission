{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import datasets as ds\n",
    "import models\n",
    "import utils\n",
    "from PoseExtraction import PoseNormalization\n",
    "# from multiPoseExtraction import MultiPoseExtraction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, scale=0.01):\n",
    "        super(Noise, self).__init__()\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        noise = (torch.randn_like(x)*self.scale).to(device)\n",
    "        return x + noise\n",
    "\n",
    "def plot_arrow_img(ax, means, orientations, img_shape, arrow_scale=2, color='r'):\n",
    "    mean_x = means[0, 0, 0].cpu().data.numpy()\n",
    "    mean_y = means[0, 1, 0].cpu().data.numpy()\n",
    "\n",
    "    rot = orientations[0].cpu().data.numpy()\n",
    "    arrow_start = (mean_x, img_shape[1] - mean_y)\n",
    "    arrow_end = (rot[0, 0]*arrow_scale, -1*rot[0, 1]*arrow_scale)\n",
    "\n",
    "    #         ax[index % row_length].arrow(arrow_start[0], arrow_start[1], arrow_end[0], arrow_end[1], \n",
    "    #                     head_width=0.5, head_length=1, fc='red', ec='r', linewidth=4, alpha=1)\n",
    "\n",
    "    ax.arrow(arrow_start[0], arrow_start[1], arrow_end[0], arrow_end[1], \n",
    "                head_width=1.5, head_length=1, fc='red', ec=color, linewidth=4, alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1, 28, 28])\n",
      "torch.Size([5000, 1])\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, dataset_details = ds.AffNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for batch_index in range(12):\n",
    "    for i, (img_batch, label) in enumerate(train_loader):\n",
    "        if i == batch_index:\n",
    "            break\n",
    "\n",
    "\n",
    "    for img_index in range(30):\n",
    "        img = img_batch[img_index:img_index+1]\n",
    "        features = cnn.layer1(img.cuda())\n",
    "        features = Noise(scale=0.0001)(features)\n",
    "        pose_norm = PoseNormalization(1, (28, 28)).to(device)\n",
    "        new_img, mu_W, orientations, confidence, theta, (L1, L2) = pose_norm(img.cuda())\n",
    "        orientation = theta[:, :, 0].unsqueeze(0)\n",
    "        # new_img = apply_theta_transform(img, theta)\n",
    "\n",
    "        row_length = 4\n",
    "        fig, ax = plt.subplots(2, 1)\n",
    "        ax[0].imshow(utils.tensor_to_numpy_img(img), cmap='gray')\n",
    "\n",
    "\n",
    "        plot_arrow_img(ax[0], mu_W, orientations, \n",
    "                           (28, 28), 5, 'r')\n",
    "\n",
    "\n",
    "\n",
    "        # print(new_img.shape)\n",
    "        ax[1].imshow(utils.tensor_to_numpy_img(new_img), cmap='gray')\n",
    "        ax[0].axis('off')\n",
    "        ax[1].axis('off')\n",
    "        plt.savefig('./AffNISTResults/fig_{}'.format(batch_index*30 + img_index))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(torch.nn.Module):\n",
    "    def __init__(self, channel_num, img_shape, num_classes=10):\n",
    "        super(PINN, self).__init__()        \n",
    "        self.pose_norm = PoseNormalization(16, (14, 14))\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(channel_num, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(int(img_shape[1]/4)*int(img_shape[0]/4)*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        \n",
    "        \n",
    "        _, mu_W, orientations, confidence, theta, (L1, L2) = self.pose_norm(x)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        # x = torch.cat([x, orientations[:, :, 0]], dim=1)\n",
    "        # x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, channel_num, img_shape):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(channel_num, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(16, 32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ReflectionPad2d((1, 1, 1, 1)),\n",
    "            nn.Conv2d(32, 32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            Noise()\n",
    "        )\n",
    "        \n",
    "        \n",
    "#         self.fc = nn.Linear(int(img_shape[1]/4)*int(img_shape[0]/4)*32, 10)\n",
    "        self.fc2 = nn.Sequential(nn.Linear(7*7*32, 20),\n",
    "                                 nn.Linear(20, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = x.view(-1, 7*7*32)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size, channel_num, height, width = dataset_details\n",
    "\n",
    "cnn_basic = CNN(channel_num=channel_num, img_shape=[height, width]).to(device)\n",
    "criterion_cnn_basic = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn = PINN(channel_num=channel_num, img_shape=[height, width]).to(device)\n",
    "criterion_cnn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TRAIN 640\n",
      "TOTAL VALIDATION 11000\n",
      "TOTAL TEST 5000\n",
      "STOPPING EPOCH\n",
      "Loss: 0.005968732805922627, Acc: 0.90625, Validation Loss: 0.006461238332770088\n",
      "STOPPING EPOCH\n",
      "Loss: 0.005559278605505824, Acc: 0.8984375, Validation Loss: 0.005578066189180721\n",
      "STOPPING EPOCH\n",
      "Loss: 0.0052946629002690315, Acc: 0.9, Validation Loss: 0.005417502731084824\n",
      "STOPPING EPOCH\n",
      "Loss: 0.0045438937842845915, Acc: 0.925, Validation Loss: 0.005176926998929544\n",
      "STOPPING EPOCH\n",
      "Loss: 0.004327024635858834, Acc: 0.915625, Validation Loss: 0.004592152014374733\n",
      "STOPPING EPOCH\n",
      "Loss: 0.004153146944008768, Acc: 0.9171875, Validation Loss: 0.005522847552191127\n",
      "STOPPING EPOCH\n",
      "Loss: 0.004434007429517805, Acc: 0.909375, Validation Loss: 0.004602416230873628\n",
      "STOPPING EPOCH\n",
      "Loss: 0.004078633664175868, Acc: 0.925, Validation Loss: 0.0039353083778511395\n",
      "STOPPING EPOCH\n",
      "Loss: 0.003632132790517062, Acc: 0.9328125, Validation Loss: 0.003572870840403167\n",
      "STOPPING EPOCH\n",
      "Loss: 0.003522759675979614, Acc: 0.9421875, Validation Loss: 0.0033842007768425074\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0005 * 2\n",
    "batch_num = 10\n",
    "epoch_num = 10\n",
    "# optimizer_pinn = torch.optim.Adam([param for param in pinn.parameters() if param.requires_grad], \n",
    "#                                   lr=learning_rate)\n",
    "optimizer_cnn = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "optimizer_cnn_basic = torch.optim.Adam(cnn_basic.parameters(), lr=learning_rate)\n",
    "# cnn_basic, cnn_basic_loss, cnn_basic_acc = utils.train_net(cnn_basic, train_loader, \n",
    "#                                                            test_loader, \n",
    "#                                                            criterion_cnn_basic, \n",
    "#                                                            optimizer_cnn_basic, batch_num, epoch_num)\n",
    "cnn, cnn_loss, cnn_acc, cnn_val_acc = utils.train_net(cnn, train_loader, test_loader, criterion_cnn, optimizer_cnn, batch_num, epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (img_batch, label_batch) in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PINN' object has no attribute 'multi_pose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d9877c5eee95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_to_numpy_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfig2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_pose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 532\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PINN' object has no attribute 'multi_pose'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADbpJREFUeJzt3W2MXOV5xvHrYr3YjbEDBmIcY9VgHBqXtoasIGlom5YXgRXJIKU0/oBclcZpGxqQoqqUfCjqh4pUJFE+VFROseK2FJIqodDKKnGtSFZUarEGF2OcYgN2wfULxgU7vNhe790PexwtsPPMsnNmztj3/yetZubc5+y5NevLZ+acmedxRAhAPmc03QCAZhB+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJTevlzs709Jihmb3cJZDKO3pTx+KoJ7NuR+G3fYOkb0kakPS3EXFvaf0ZmqmrfE0nuwRQsCk2THrdKb/stz0g6a8l3ShpiaQVtpdM9fcB6K1O3vNfKWlnRLwYEcckPSxpeT1tAei2TsI/X9LL4x6/Ui17F9urbA/bHj6uox3sDkCdun62PyJWR8RQRAwNanq3dwdgkjoJ/x5JC8Y9vrBaBuAU0En4n5S02PZFts+U9HlJj9XTFoBum/KlvogYsX27pMc1dqlvTURsq60zAF3V0XX+iFgnaV1NvQDoIT7eCyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUj0duhu9N23BhcX66GuHyvW33qqzHfQRjvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTX+U8FZwyUy798acva4LdeK277+td+sVif+fTLxXq8/XaxPrJkYcva4O5Xi9uOHj7S0b5jZKRYz44jP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k1dF1ftu7JB2RdELSSEQM1dFUNgOzZxfrR679eLE+7Q/3taz98yX/Wtz2t778O8X6z80sXyv/pdnla/VS6/rQzBeLWz7wv79WrG994rJi/SPDoy1rZz+5t7jtyK7/KdZPB3V8yOc3I+JgDb8HQA/xsh9IqtPwh6Qf2t5se1UdDQHojU5f9l8dEXtsf0TSets/iYiN41eo/lNYJUkz9KEOdwegLh0d+SNiT3V7QNIjkq6cYJ3VETEUEUODmt7J7gDUaMrhtz3T9qyT9yVdL+nZuhoD0F2dvOyfK+kR2yd/zz9GxL/V0hWArnNE9Gxnsz0nrvI1PdvfqeLQ732qWF92x8Zi/fpZW1vWfn/zyuK277zR5q3YCRfLcz76RrH+qQt2t6xteW1+cdsrziuPJTB/+uvF+pETM1rWNr22sLjtW3/z0WL9rH/aVKw3ZVNs0OE4VP6jVbjUByRF+IGkCD+QFOEHkiL8QFKEH0iKobv7wOvXloeg/pNzNxfrSx++s2XtkgfLw18PHGz9dWBJ0rTysOGjB8pf6Hyh8E/sw3OOFbd9fm/5MvSOX/hEsX7o8nNa1o7NanMJ89DRYv10wJEfSIrwA0kRfiApwg8kRfiBpAg/kBThB5LiOn8vtJlie3BbeXiz6b8xWKw//tv3taz92SeXF7cdjfL17qeeWVSsz9pZ/lru/H9pPUT2yM6Xitu2E8/+pFg/uzC0jKd3NqpU774I3z0c+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKYbuPgUMLL64WH9pxQUta0cvLn8v/UOz3ynWr5hXHj77L+evK9aveeKPWtYWfbk8lsCJ/QeKdbwfQ3cDaIvwA0kRfiApwg8kRfiBpAg/kBThB5Jqe53f9hpJn5V0ICIuq5bNkfRdSQsl7ZJ0S0T8X7udcZ2/9zx4ZrE+ML/1ZwQk6c2Pzy3Wl/xF6+nBJWmaT7SsPf+FjxW3jae3Fet4v7qv839H0g3vWXaXpA0RsVjShuoxgFNI2/BHxEZJh96zeLmktdX9tZJuqrkvAF021ff8cyPi5PhM+ySVXxsC6Dsdn/CLsZMGLU8c2F5le9j28HGd/vOfAaeKqYZ/v+15klTdtvwGRkSsjoihiBgaVGeDJgKoz1TD/5ikldX9lZIeracdAL3SNvy2H5L0hKRLbb9i+zZJ90q6zvYOSddWjwGcQtqO2x8RK1qUuGBfGZg9u1j3ua3niZekkZd219nOu8SJ1tfZJWn07LOK9Xf+uPzxjfvmbSzWf+Uf7mhZW7yrPO5+uXN0ik/4AUkRfiApwg8kRfiBpAg/kBThB5Jiiu4aHPvEJcX6izeXp9i+dM3MYt1vHyvW376o9aXE15aU933jrf9RrH9t7pZi/XMvLCvWF333cMvaiTda19B9HPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICmu89dgZMZAsf7V68pjnfznVYuK9bMH3yrWbzp7c+ttzygPnfZmlP8JXPT4HxTrH7u//BkEPV0e2hvN4cgPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0m1naK7TqfrFN2eXp6J6NWVVxTrsz63t1j/1fNfLNafOHhRy9ru7eUpuBesL//9z3qyPKz4yL79xTp6q+4pugGchgg/kBThB5Ii/EBShB9IivADSRF+IKm21/ltr5H0WUkHIuKyatk9kr4g6dVqtbsjYl27nZ2u1/nbOWPWrGLdF5xf/gXt/kYnRlvWRg8eKm47+mZ5rACNMlH2qaTu6/zfkXTDBMu/GRFLq5+2wQfQX9qGPyI2SiofPgCccjp5z3+77Wdsr7Hder4oAH1pquG/X9IiSUsl7ZX09VYr2l5le9j28HGVx5MD0DtTCn9E7I+IExExKunbkq4srLs6IoYiYmhQ5S/AAOidKYXf9rxxD2+W9Gw97QDolbZDd9t+SNJnJJ1n+xVJfy7pM7aXSgpJuyR9sYs9AuiCtuGPiBUTLH6gC72ctkaPHCmv0K4OdAGf8AOSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k1Tb8thfY/pHt52xvs31HtXyO7fW2d1S353S/XQB1mcyRf0TSVyJiiaRPSvqS7SWS7pK0ISIWS9pQPQZwimgb/ojYGxFPVfePSNouab6k5ZLWVqutlXRTt5oEUL8P9J7f9kJJl0vaJGluROytSvskza21MwBdNenw2z5L0vcl3RkRh8fXIiIkRYvtVtketj18XEc7ahZAfSYVftuDGgv+gxHxg2rxftvzqvo8SQcm2jYiVkfEUEQMDWp6HT0DqMFkzvZb0gOStkfEN8aVHpO0srq/UtKj9bcHoFumTWKdT0u6VdJW21uqZXdLulfS92zfJmm3pFu60yKAbmgb/oj4sSS3KF9TbzsAeoVP+AFJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSaht+2wts/8j2c7a32b6jWn6P7T22t1Q/y7rfLoC6TJvEOiOSvhIRT9meJWmz7fVV7ZsRcV/32gPQLW3DHxF7Je2t7h+xvV3S/G43BqC7PtB7ftsLJV0uaVO16Hbbz9heY/ucFtussj1se/i4jnbULID6TDr8ts+S9H1Jd0bEYUn3S1okaanGXhl8faLtImJ1RAxFxNCgptfQMoA6TCr8tgc1FvwHI+IHkhQR+yPiRESMSvq2pCu71yaAuk3mbL8lPSBpe0R8Y9zyeeNWu1nSs/W3B6BbJnO2/9OSbpW01faWatndklbYXiopJO2S9MWudAigKyZztv/HkjxBaV397QDoFT7hByRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSMoR0bud2a9K2j1u0XmSDvasgQ+mX3vr174kepuqOnv7+Yg4fzIr9jT879u5PRwRQ401UNCvvfVrXxK9TVVTvfGyH0iK8ANJNR3+1Q3vv6Rfe+vXviR6m6pGemv0PT+A5jR95AfQkEbCb/sG2/9te6ftu5rooRXbu2xvrWYeHm64lzW2D9h+dtyyObbX295R3U44TVpDvfXFzM2FmaUbfe76bcbrnr/stz0g6XlJ10l6RdKTklZExHM9baQF27skDUVE49eEbf+6pJ9K+ruIuKxa9leSDkXEvdV/nOdExJ/2SW/3SPpp0zM3VxPKzBs/s7SkmyT9rhp87gp93aIGnrcmjvxXStoZES9GxDFJD0ta3kAffS8iNko69J7FyyWtre6v1dg/np5r0VtfiIi9EfFUdf+IpJMzSzf63BX6akQT4Z8v6eVxj19Rf035HZJ+aHuz7VVNNzOBudW06ZK0T9LcJpuZQNuZm3vpPTNL981zN5UZr+vGCb/3uzoirpB0o6QvVS9v+1KMvWfrp8s1k5q5uVcmmFn6Z5p87qY643Xdmgj/HkkLxj2+sFrWFyJiT3V7QNIj6r/Zh/efnCS1uj3QcD8/008zN080s7T64Lnrpxmvmwj/k5IW277I9pmSPi/psQb6eB/bM6sTMbI9U9L16r/Zhx+TtLK6v1LSow328i79MnNzq5ml1fBz13czXkdEz38kLdPYGf8XJH21iR5a9HWxpP+qfrY13ZukhzT2MvC4xs6N3CbpXEkbJO2Q9O+S5vRRb38vaaukZzQWtHkN9Xa1xl7SPyNpS/WzrOnnrtBXI88bn/ADkuKEH5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpP4fpiNUb0j+VFMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a6207f5c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a61e54ac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_index = 9\n",
    "img = img_batch[img_index:img_index+1]\n",
    "\n",
    "features = cnn.layer1(img.cuda())\n",
    "features.shape\n",
    "\n",
    "row_length = 4\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(utils.tensor_to_numpy_img(img))\n",
    "fig2, ax2 = plt.subplots(4, 4)\n",
    "means, orientations, (L1, L2) = cnn.multi_pose(features)\n",
    "print(features.shape)\n",
    "print(means.shape)\n",
    "print(orientations.shape)\n",
    "\n",
    "for index, activation_map in enumerate(features[0]):\n",
    "    current_ax = ax2[index % 4, index // 4]\n",
    "    current_ax.imshow(utils.tensor_to_numpy_img(activation_map))\n",
    "    plot_arrow_img(current_ax, means[:, index], orientations[:, index], \n",
    "                   (14, 14), 2, 'y')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
